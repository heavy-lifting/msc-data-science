{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnHJABKUv6ZYC6mGpJ/Ekc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heavy-lifting/msc-data-science/blob/main/cop528-ai-applied-machine-learning/AI_05_lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 05. Neural Network\n",
        "## Tutorial 01. Simple neural network example\n",
        "### 1) loading dataset"
      ],
      "metadata": {
        "id": "__kHfbX1HzId"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBOrcAADHuOy"
      },
      "outputs": [],
      "source": [
        "# Use the iris dataset as an example\n",
        "import numpy as np # for numpy\n",
        "\n",
        "# Now import a multiclassification model from a neural network for training multiclassification data\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Now import the libraries in sklearn that are used to evaluate the prediction metrics,\n",
        "# such as confusion matrices and classification reports\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "iris_data = load_iris()\n",
        "\n",
        "X = iris_data.data\n",
        "y = iris_data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) calling the model in `sklearn`\n",
        "\n",
        "#### Main parameters.\n",
        "- `hidden_layer_sizes`: number of hidden layer cells (tuples)\n",
        "  - e.g. (100,100,100,50)\n",
        "- `activation` : activation function\n",
        "  - `{'identity', 'logistic', 'tanh', 'relu'}` - default `'relu'`\n",
        "    - `identity`: f(x) = x\n",
        "    - `logistic`: 1/(1+exp(-x))\n",
        "    - `tanh`: tanh(x)\n",
        "    - `relu`: max(0, x)\n",
        "- `solver` : solver\n",
        "  - `{'lbfgs', 'sgd', 'adam'}` - default `'adam '`\n",
        "    - `lbfgs`: newton method\n",
        "    - `sgd`: stochastic gradient descent\n",
        "    - `adam`: adaptive momemtum\n",
        "- `alpha` : L2 regularization parameter (optional)\n",
        "  - float - default `0.0001`\n",
        "- `batch_size` : batch size (optional)\n",
        "  - default `'auto'` (in this case, `batch_size=min(200, n_samples)`\n",
        "  - not applicable to `'lbfgs'`\n",
        "- `learning_rate` : learning rate\n",
        "  - `{'constant', 'invscaling', 'adaptive'}` - default `'constant'`\n",
        "  -  only for gradient descent `sgd`\n",
        "- `learning_rate_init` : initial value of the learning rate (optional)\n",
        "  - default 0.001\n",
        "  - only for `sgd` or `adam`\n",
        "- `power_t` : descent exponent (optional)\n",
        "  - default `0.5`\n",
        "  - applies to `'invscaling'`,`learning_rate_init/pow(t,power_t)`, `sgd` only\n",
        "- `max_iter` : maximum number of iterations (optional)\n",
        "  - default `200`\n",
        "  - number of iterator convergence iterations\n",
        "  - for `sgd`/`adam`, represents the number of epochs, not the number of descent steps\n",
        "- `shuffle` : per iteration, whether to shuffle or not\n",
        "  - (optional)\n",
        "  - default `True`\n",
        "  - only for `sgd` or `adam`\n",
        "- `random_state`:\n",
        "  - default `None`\n",
        "  - if `int`: random number generator seed\n",
        "  - if `RandomStates` instance: random number generator\n",
        "  - if `None`: np.random\n",
        "- `tol` : tolerance\n",
        "  - (optional)\n",
        "  - default `1e-4`\n",
        "  - stop iterating if loss does not reach this value in two consecutive iterations unless set to 'adaptive', otherwise\n",
        "- `beta_1` : adam exponent decay parameter 1\n",
        "  - (optional)\n",
        "  - default `0.9`\n",
        "- `beta_2` : adam exponential decay parameter 2\n",
        "  - (optional)\n",
        "  - default `0.999`\n",
        "- `epsilon` : adam numerical stability value\n",
        "  - (optional)\n",
        "  - default `1e-8`"
      ],
      "metadata": {
        "id": "-iZ5_ilLIqc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiple parameters in parentheses, if not written, default values are used, we generally want to build the hidden\n",
        "# layer structure, debug the regularization parameters and set the maximum number of iterations\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(20),alpha=0.01,max_iter=300)\n",
        "# The model can be trained by calling the fit function. The general method of training by calling the model function is fit()\n",
        "mlp.fit(X_train,y_train) # Here the y value needs to be reduced to a one-dimensional array\n",
        "# This is how the model is trained, and we can then call a variety of functions to get the trained parameters\n",
        "# For example, to get the accuracy rate\n",
        "print('The accuracy of the test set is:',mlp.score(X_test,y_test))\n",
        "# e.g. output the current Current value of the loss function\n",
        "print('The Current value of the loss function of the training set is:',mlp.loss_)\n",
        "# For example, output the weights of each theta\n",
        "print('The weight value :',mlp.coefs_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKpCW67eMNmC",
        "outputId": "00f2be16-5a91-488d-b75a-5af15479dea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of the test set is: 0.9333333333333333\n",
            "The Current value of the loss function of the training set is: 0.3066901526899486\n",
            "The weight value : [array([[ 2.58240406e-01, -1.19535346e-01, -1.98103478e-07,\n",
            "         1.57073069e-01, -2.61949767e-01, -3.61797988e-01,\n",
            "        -6.39297514e-02,  1.74161166e-01, -1.28267176e-01,\n",
            "         5.24670283e-01, -1.73435031e-01, -1.26038637e-01,\n",
            "         4.26292038e-01, -1.80728203e-01, -2.83163460e-01,\n",
            "         2.83861358e-01, -2.41813353e-01,  2.49312578e-01,\n",
            "        -9.28998131e-02, -6.20153393e-03],\n",
            "       [ 1.54526626e-02,  4.33399444e-01, -1.03722306e-01,\n",
            "         5.58283933e-01,  1.95491250e-01, -2.16083703e-01,\n",
            "        -4.54670595e-04,  2.03021198e-01, -1.06721385e-01,\n",
            "        -2.59561999e-01, -5.31573814e-02, -1.85657201e-08,\n",
            "        -5.46515987e-01,  6.61348936e-01,  2.38983310e-01,\n",
            "        -6.30919103e-02,  1.71075054e-01,  4.21298041e-01,\n",
            "        -2.08579390e-01,  2.54928715e-01],\n",
            "       [ 4.05796647e-01,  3.22098252e-01, -1.00899634e-01,\n",
            "        -4.96301847e-01,  1.13713593e-01,  6.12167728e-01,\n",
            "        -1.71394631e-01, -7.03439476e-02,  1.60441211e-01,\n",
            "        -3.04991677e-01, -3.36729829e-03,  1.53461156e-02,\n",
            "         1.92428865e-01, -1.35683759e-01,  3.69645696e-01,\n",
            "         1.77538660e-02,  1.24137826e-01, -1.22629208e-01,\n",
            "        -3.29647713e-05,  7.91819247e-02],\n",
            "       [-2.73645236e-01,  2.99194340e-01,  2.08344179e-01,\n",
            "        -2.94596393e-01, -3.55764841e-01,  6.27778410e-01,\n",
            "        -1.04977944e-01,  1.07850903e-01,  2.42968356e-01,\n",
            "        -2.05930647e-01,  9.79835700e-02,  4.97730294e-02,\n",
            "         4.72168890e-01, -4.72431325e-01,  6.92225758e-01,\n",
            "        -3.84445075e-01, -4.14617096e-02, -3.19449149e-01,\n",
            "         1.12327767e-02, -2.83821083e-01]]), array([[-2.13007794e-01, -3.01160237e-01,  4.53025246e-01],\n",
            "       [-2.87143453e-01,  2.77310383e-01,  3.01433202e-01],\n",
            "       [-2.33540947e-01, -1.31808237e-01, -2.20993816e-02],\n",
            "       [ 7.66675189e-03, -8.43873435e-01, -5.51039117e-01],\n",
            "       [-2.35079524e-01, -2.00273771e-01,  3.05446123e-01],\n",
            "       [-8.38995465e-02, -4.73675257e-01,  3.42295400e-01],\n",
            "       [ 1.17577948e-01, -6.37024754e-04, -1.59310458e-01],\n",
            "       [-3.46349137e-01,  2.78938061e-01,  3.55978890e-01],\n",
            "       [-1.81151093e-01, -2.98211846e-01,  1.94068156e-01],\n",
            "       [ 1.58215824e-01,  5.24813796e-01, -4.50397150e-01],\n",
            "       [-4.83138735e-02, -1.51938411e-01, -4.77435036e-02],\n",
            "       [ 1.04010952e-01, -4.59122857e-02,  1.34466982e-01],\n",
            "       [ 5.59359108e-02,  2.42405403e-01,  3.27685975e-01],\n",
            "       [ 7.32361547e-01, -4.23193245e-01, -2.51088672e-02],\n",
            "       [-3.45450569e-01,  7.82779766e-02,  2.00574735e-01],\n",
            "       [ 3.17302293e-01,  2.61698954e-02, -5.09635436e-01],\n",
            "       [-2.59022702e-02, -1.58867101e-08,  3.33716076e-09],\n",
            "       [ 5.29206362e-01, -1.15674591e-01, -5.59558700e-01],\n",
            "       [-2.64870542e-02,  1.81764576e-01,  1.59268779e-01],\n",
            "       [ 4.91624036e-02,  6.22176617e-01, -4.20776947e-01]])]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) Confusion matrix and classification reports"
      ],
      "metadata": {
        "id": "n2O9imqdMlEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The confusion matrix and classification report is an indicator of the predicted and true values\n",
        "# The confusion matrix provides a visual indication of the number of correct and incorrect classifications, and the\n",
        "# category to which the correct samples were incorrectly classified\n",
        "matrix_test = confusion_matrix(y_test,mlp.predict(X_test))\n",
        "print('The confusion matrix for the training set is:\\n',matrix_test)\n",
        "# There are multiple metrics in the classification report to evaluate how good the prediction is.\n",
        "# '''\n",
        "# TP: Prediction is 1 (Positive), actual is also 1 (Truth-prediction is correct)\n",
        "# TN: predicted 0 (Negative), also 0 (Truth - predicted correctly)\n",
        "# FP: predicted 1 (Positive), actually 0 (False - wrong prediction)\n",
        "# FN: Prediction is 0 (Negative), actual is 1 (False-prediction is wrong)\n",
        "# '''\n",
        "report_test = classification_report(y_test,mlp.predict(X_test))\n",
        "print(f'The classification report for the training set is: \\n {report_test}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ofm3eskmMoDd",
        "outputId": "98a57c7b-3026-44bf-ebfa-6f813859eb65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The confusion matrix for the training set is:\n",
            " [[16  0  0]\n",
            " [ 0 15  3]\n",
            " [ 0  0 11]]\n",
            "The classification report for the training set is: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        16\n",
            "           1       1.00      0.83      0.91        18\n",
            "           2       0.79      1.00      0.88        11\n",
            "\n",
            "    accuracy                           0.93        45\n",
            "   macro avg       0.93      0.94      0.93        45\n",
            "weighted avg       0.95      0.93      0.93        45\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 01. Neural network classification experiments\n",
        "- use `sklearn` to define a MLP NN and use it to train a model for seeds quality classification_report\n",
        "- analyse with different numbers of layers and neurons on each layer\n",
        "### 1) load the data\n",
        "(bit confused here since the doc says this is a 2-class binary classification problem, but then the def of the data set says there are three classes.... will check now - yep, def three classes. Lets just get on with it though)"
      ],
      "metadata": {
        "id": "TQ7WB5fnNV-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/lborohfang/COP528AML_Files/main/seeds_dataset.csv\")\n",
        "print(df.head(10))\n",
        "\n",
        "seeds_data = np.asarray(df.iloc[:,:-1])\n",
        "seeds_label= np.asarray(df.iloc[:,-1])\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        " seeds_data, seeds_label, test_size=0.3, random_state=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvI38LL9NHbV",
        "outputId": "5b09802b-364d-42dc-8268-4e2bfda8997f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Area  Perimeter  Compactness  Length of kernel  Width of Kernel  \\\n",
            "0  15.26      14.84       0.8710             5.763            3.312   \n",
            "1  14.88      14.57       0.8811             5.554            3.333   \n",
            "2  14.29      14.09       0.9050             5.291            3.337   \n",
            "3  13.84      13.94       0.8955             5.324            3.379   \n",
            "4  16.14      14.99       0.9034             5.658            3.562   \n",
            "5  14.38      14.21       0.8951             5.386            3.312   \n",
            "6  14.69      14.49       0.8799             5.563            3.259   \n",
            "7  14.11      14.10       0.8911             5.420            3.302   \n",
            "8  16.63      15.46       0.8747             6.053            3.465   \n",
            "9  16.44      15.25       0.8880             5.884            3.505   \n",
            "\n",
            "   Asymmetry Coef.  Length of groove  Class  \n",
            "0            2.221             5.220      1  \n",
            "1            1.018             4.956      1  \n",
            "2            2.699             4.825      1  \n",
            "3            2.259             4.805      1  \n",
            "4            1.355             5.175      1  \n",
            "5            2.462             4.956      1  \n",
            "6            3.586             5.219      1  \n",
            "7            2.700             5.000      1  \n",
            "8            2.040             5.877      1  \n",
            "9            1.969             5.533      1  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lets just start with a basic model the same as the example\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(20), alpha= 0.01, max_iter=300)\n",
        "\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# For example, to get the accuracy rate\n",
        "print('The accuracy of the test set is:',mlp.score(X_test,y_test))\n",
        "# e.g. output the current Current value of the loss function\n",
        "print('The Current value of the loss function of the training set is:',mlp.loss_)\n",
        "# For example, output the weights of each theta - not printing this cause it's massive and not super meaningful to me\n",
        "# (maybe useful in CW though if we need to analyse in detail)\n",
        "# print('The weight value :',mlp.coefs_)\n",
        "\n",
        "# WAIT tho - as I rerun this we are getting v diff outputs...\n",
        "# it's also complaining about no convergin (most of the time)\n",
        "\n",
        "matrix_test = confusion_matrix(y_test,mlp.predict(X_test))\n",
        "print('The confusion matrix for the training set is:\\n',matrix_test)\n",
        "\n",
        "report_test = classification_report(y_test,mlp.predict(X_test))\n",
        "print(f'The classification report for the training set is: \\n {report_test}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yx7TKusaOTpo",
        "outputId": "5601cdd0-273d-4cd5-d0d7-a86ce9c95c3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of the test set is: 0.3492063492063492\n",
            "The Current value of the loss function of the training set is: 0.9946203001580677\n",
            "The confusion matrix for the training set is:\n",
            " [[ 2 10  7]\n",
            " [16  3  8]\n",
            " [ 0  0 17]]\n",
            "The classification report for the training set is: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.11      0.11      0.11        19\n",
            "           2       0.23      0.11      0.15        27\n",
            "           3       0.53      1.00      0.69        17\n",
            "\n",
            "    accuracy                           0.35        63\n",
            "   macro avg       0.29      0.41      0.32        63\n",
            "weighted avg       0.28      0.35      0.28        63\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lets add an extra layer of 20 neurons\n",
        "mlp2 = MLPClassifier(hidden_layer_sizes=(20,20), alpha= 0.01, max_iter=300)\n",
        "\n",
        "mlp2.fit(X_train, y_train)\n",
        "\n",
        "# For example, to get the accuracy rate\n",
        "print('The accuracy of the test set is:',mlp2.score(X_test,y_test))\n",
        "# e.g. output the current Current value of the loss function\n",
        "print('The Current value of the loss function of the training set is:',mlp2.loss_)\n",
        "# For example, output the weights of each theta\n",
        "# print('The weight value :',mlp2.coefs_)\n",
        "\n",
        "# that's quite a large improvement (except is it tho.... it's all very variable)\n",
        "\n",
        "matrix_test = confusion_matrix(y_test,mlp2.predict(X_test))\n",
        "print('The confusion matrix for the training set is:\\n',matrix_test)\n",
        "\n",
        "report_test = classification_report(y_test,mlp2.predict(X_test))\n",
        "print(f'The classification report for the training set is: \\n {report_test}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diabH1J-OuhT",
        "outputId": "347e40a2-b677-4112-c1a7-c7d20333add2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of the test set is: 0.6507936507936508\n",
            "The Current value of the loss function of the training set is: 0.8940093183031536\n",
            "The confusion matrix for the training set is:\n",
            " [[ 5 12  2]\n",
            " [ 7 20  0]\n",
            " [ 1  0 16]]\n",
            "The classification report for the training set is: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.38      0.26      0.31        19\n",
            "           2       0.62      0.74      0.68        27\n",
            "           3       0.89      0.94      0.91        17\n",
            "\n",
            "    accuracy                           0.65        63\n",
            "   macro avg       0.63      0.65      0.63        63\n",
            "weighted avg       0.62      0.65      0.63        63\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lets massively increasse the iters\n",
        "mlp3 = MLPClassifier(hidden_layer_sizes=(20,20), alpha= 0.01, max_iter=3000)\n",
        "\n",
        "mlp3.fit(X_train, y_train)\n",
        "\n",
        "# For example, to get the accuracy rate\n",
        "print('The accuracy of the test set is:',mlp3.score(X_test,y_test))\n",
        "# e.g. output the current Current value of the loss function\n",
        "print('The Current value of the loss function of the training set is:',mlp3.loss_)\n",
        "# For example, output the weights of each theta\n",
        "# print('The weight value :',mlp2.coefs_)\n",
        "\n",
        "# that's quite a large improvement (except is it tho.... it's all very variable)\n",
        "\n",
        "# this seems much more stable at around 0.95 accuracy\n",
        "\n",
        "matrix_test = confusion_matrix(y_test,mlp3.predict(X_test))\n",
        "print('The confusion matrix for the training set is:\\n',matrix_test)\n",
        "\n",
        "report_test = classification_report(y_test,mlp3.predict(X_test))\n",
        "print(f'The classification report for the training set is: \\n {report_test}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibWkM8RDPfs-",
        "outputId": "fe222b61-60d6-47fe-d5f7-561673ae72a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of the test set is: 0.9523809523809523\n",
            "The Current value of the loss function of the training set is: 0.05148043832079875\n",
            "The confusion matrix for the training set is:\n",
            " [[18  1  0]\n",
            " [ 2 25  0]\n",
            " [ 0  0 17]]\n",
            "The classification report for the training set is: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.90      0.95      0.92        19\n",
            "           2       0.96      0.93      0.94        27\n",
            "           3       1.00      1.00      1.00        17\n",
            "\n",
            "    accuracy                           0.95        63\n",
            "   macro avg       0.95      0.96      0.96        63\n",
            "weighted avg       0.95      0.95      0.95        63\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# so now lets try more iters and much bigger layers\n",
        "mlp4 = MLPClassifier(hidden_layer_sizes=(100,100), alpha= 0.01, max_iter=3000)\n",
        "\n",
        "mlp4.fit(X_train, y_train)\n",
        "\n",
        "# For example, to get the accuracy rate\n",
        "print('The accuracy of the test set is:',mlp4.score(X_test,y_test))\n",
        "# e.g. output the current Current value of the loss function\n",
        "print('The Current value of the loss function of the training set is:',mlp4.loss_)\n",
        "\n",
        "# this isn't really much better than above\n",
        "\n",
        "matrix_test = confusion_matrix(y_test,mlp4.predict(X_test))\n",
        "print('The confusion matrix for the training set is:\\n',matrix_test)\n",
        "\n",
        "report_test = classification_report(y_test,mlp4.predict(X_test))\n",
        "print(f'The classification report for the training set is: \\n {report_test}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOxe6MScPvOs",
        "outputId": "27279881-d603-4149-daa7-69fc53729ef6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of the test set is: 0.9523809523809523\n",
            "The Current value of the loss function of the training set is: 0.07582817630172324\n",
            "The confusion matrix for the training set is:\n",
            " [[17  1  1]\n",
            " [ 1 26  0]\n",
            " [ 0  0 17]]\n",
            "The classification report for the training set is: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.94      0.89      0.92        19\n",
            "           2       0.96      0.96      0.96        27\n",
            "           3       0.94      1.00      0.97        17\n",
            "\n",
            "    accuracy                           0.95        63\n",
            "   macro avg       0.95      0.95      0.95        63\n",
            "weighted avg       0.95      0.95      0.95        63\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So is this because of the randomness of starting points, splits etc? If I use a random seed does it increase stability across runs?"
      ],
      "metadata": {
        "id": "6DKKUxBZP7wb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# go back to our original model (which was pretty unstable)\n",
        "mlp5 = MLPClassifier(hidden_layer_sizes=(20), alpha= 0.01, max_iter=300, random_state=77)\n",
        "\n",
        "mlp5.fit(X_train, y_train)\n",
        "\n",
        "# For example, to get the accuracy rate\n",
        "print('The accuracy of the test set is:',mlp5.score(X_test,y_test))\n",
        "# e.g. output the current Current value of the loss function\n",
        "print('The Current value of the loss function of the training set is:',mlp5.loss_)\n",
        "# For example, output the weights of each theta - not printing this cause it's massive and not super meaningful to me\n",
        "# (maybe useful in CW though if we need to analyse in detail)\n",
        "# print('The weight value :',mlp.coefs_)\n",
        "\n",
        "matrix_test = confusion_matrix(y_test,mlp5.predict(X_test))\n",
        "print('The confusion matrix for the training set is:\\n',matrix_test)\n",
        "\n",
        "report_test = classification_report(y_test,mlp5.predict(X_test))\n",
        "print(f'The classification report for the training set is: \\n {report_test}')\n",
        "\n",
        "# now I've fixed the random state this is coming in the same every time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mI4K51AcP6-6",
        "outputId": "b85d8f84-7a0e-47d8-cd85-591b0f6dccc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of the test set is: 0.6666666666666666\n",
            "The Current value of the loss function of the training set is: 0.8378363840568379\n",
            "The confusion matrix for the training set is:\n",
            " [[ 6 10  3]\n",
            " [ 2 20  5]\n",
            " [ 1  0 16]]\n",
            "The classification report for the training set is: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.67      0.32      0.43        19\n",
            "           2       0.67      0.74      0.70        27\n",
            "           3       0.67      0.94      0.78        17\n",
            "\n",
            "    accuracy                           0.67        63\n",
            "   macro avg       0.67      0.67      0.64        63\n",
            "weighted avg       0.67      0.67      0.64        63\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 02. Neural network classification and visualisation\n",
        "- similar to how we used a mesh grid to visualise the classifircation boundary of SVM yday, visualise the boundaries of MLP NNs with 1 and 2 hidden layers"
      ],
      "metadata": {
        "id": "IcpWTLT7RJJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model 1\n",
        "mlp_vis_1 = MLPClassifier(hidden_layer_sizes=(20), alpha= 0.01, max_iter=300, random_state=77)\n",
        "\n",
        "mlp_vis_1.fit(X_train, y_train)\n",
        "\n",
        "print('The accuracy of the test set is:',mlp_vis_1.score(X_test,y_test))\n",
        "\n",
        "print('The Current value of the loss function of the training set is:',mlp_vis_1.loss_)\n",
        "\n",
        "matrix_test = confusion_matrix(y_test,mlp_vis_1.predict(X_test))\n",
        "print('The confusion matrix for the training set is:\\n',matrix_test)\n",
        "\n",
        "report_test = classification_report(y_test,mlp_vis_1.predict(X_test))\n",
        "print(f'The classification report for the training set is: \\n {report_test}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8N4VSOVDQO5Y",
        "outputId": "b029b676-589b-4c26-c2fc-2d71fcd172bc"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of the test set is: 0.6666666666666666\n",
            "The Current value of the loss function of the training set is: 0.8378363840568379\n",
            "The confusion matrix for the training set is:\n",
            " [[ 6 10  3]\n",
            " [ 2 20  5]\n",
            " [ 1  0 16]]\n",
            "The classification report for the training set is: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.67      0.32      0.43        19\n",
            "           2       0.67      0.74      0.70        27\n",
            "           3       0.67      0.94      0.78        17\n",
            "\n",
            "    accuracy                           0.67        63\n",
            "   macro avg       0.67      0.67      0.64        63\n",
            "weighted avg       0.67      0.67      0.64        63\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model 2\n",
        "mlp_vis_2 = MLPClassifier(hidden_layer_sizes=(20,20), alpha= 0.01, max_iter=300, random_state=77)\n",
        "\n",
        "mlp_vis_2.fit(X_train, y_train)\n",
        "\n",
        "print('The accuracy of the test set is:',mlp_vis_2.score(X_test,y_test))\n",
        "\n",
        "print('The Current value of the loss function of the training set is:',mlp_vis_2.loss_)\n",
        "\n",
        "matrix_test = confusion_matrix(y_test,mlp_vis_2.predict(X_test))\n",
        "print('The confusion matrix for the training set is:\\n',matrix_test)\n",
        "\n",
        "report_test = classification_report(y_test,mlp_vis_2.predict(X_test))\n",
        "print(f'The classification report for the training set is: \\n {report_test}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFX3pvlERrl5",
        "outputId": "2ff20e06-13de-4890-f9e2-a28995dfa425"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of the test set is: 0.9047619047619048\n",
            "The Current value of the loss function of the training set is: 0.2716486472807431\n",
            "The confusion matrix for the training set is:\n",
            " [[16  1  2]\n",
            " [ 2 24  1]\n",
            " [ 0  0 17]]\n",
            "The classification report for the training set is: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.89      0.84      0.86        19\n",
            "           2       0.96      0.89      0.92        27\n",
            "           3       0.85      1.00      0.92        17\n",
            "\n",
            "    accuracy                           0.90        63\n",
            "   macro avg       0.90      0.91      0.90        63\n",
            "weighted avg       0.91      0.90      0.90        63\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- not sure this is the best choice of model as they seem quite similar - can tweak tho if needed\n",
        "- ok I changed the seed and it's p diff now. feel like the seed shouldn't make that much difference......\n",
        "- let's forge on for now"
      ],
      "metadata": {
        "id": "_s9YTbKOSEWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# functions for creating class boundaries\n",
        "def make_meshgrid(x, y, h=.02):\n",
        "  x_min, x_max = x.min() - 1, x.max() + 1\n",
        "  y_min, y_max = y.min() - 1, y.max() + 1\n",
        "  xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "  return xx, yy\n",
        "\n",
        "def plot_contours(ax, clf, xx, yy, **params):\n",
        "  Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "  Z = Z.reshape(xx.shape)\n",
        "  out = ax.contourf(xx, yy, Z, **params)\n",
        "  return out\n",
        "\n",
        "def plot_mlp(ax, mlp, xx, yy, **params):\n",
        "  Z = mlp.predict(X_test)\n",
        "  Z = Z.reshape(xx.shape)\n",
        "  out = ax.contourf(xx, yy, Z, **params)\n",
        "  return out"
      ],
      "metadata": {
        "id": "YcnIf0jQSWD2"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is stuff for the SVM\n",
        "# SVM\n",
        "# model = svm.SVC(kernel=\"poly\", degree=3)\n",
        "# clf = model.fit(X, y)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# create the fig\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# title for the plots\n",
        "title = ('Decision surface of MLP NNs with different numbers of layers')\n",
        "\n",
        "# Set-up grid for plotting.\n",
        "X0, X1 = X[:, 0], X[:, 1]\n",
        "xx, yy = make_meshgrid(X0, X1)\n",
        "plot_mlp(ax, mlp_vis_1, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
        "ax.scatter(X0, X1, c=y, cmap=plt.cm.coolwarm, s=20, edgecolors=\"k\")\n",
        "ax.set_ylabel(\"{}\".format(feature_names[0]))\n",
        "ax.set_xlabel(\"{}\".format(feature_names[1]))\n",
        "ax.set_xticks(())\n",
        "ax.set_yticks(())\n",
        "ax.set_title(title)\n",
        "plt.show()\n",
        "# print(f'SVM accuracy_score:{accuracy_score(y, clf.predict(X))}')\n",
        "\n",
        "# # kNN\n",
        "# from sklearn import neighbors\n",
        "# clf_kNN = neighbors.KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
        "# clf_kNN.fit(X, y)\n",
        "# y_pred=clf_kNN.predict(X)\n",
        "# fig, ax = plt.subplots()\n",
        "\n",
        "# # title for the plots\n",
        "# title = ('Decision surface of kNN')\n",
        "\n",
        "# # Set-up grid for plotting.\n",
        "# X0, X1 = X[:, 0], X[:, 1]\n",
        "# xx, yy = make_meshgrid(X0, X1)\n",
        "# plot_contours(ax, clf_kNN, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
        "# ax.scatter(X0, X1, c=y, cmap=plt.cm.coolwarm, s=20, edgecolors=\"k\")\n",
        "# ax.set_ylabel(\"{}\".format(feature_names[0]))\n",
        "# ax.set_xlabel(\"{}\".format(feature_names[1]))\n",
        "# ax.set_xticks(())\n",
        "# ax.set_yticks(())\n",
        "# ax.set_title(title)\n",
        "# plt.show()\n",
        "# print(f'kNN accuracy_score:{accuracy_score(y, y_pred)}')\n",
        "\n",
        "# k so this is v reliant on the functions above. I would NOT have worked this out."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 769
        },
        "id": "Yz4P7jIbSYuO",
        "outputId": "9ccfc72c-0399-45d6-e618-23bf292bb890"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "cannot reshape array of size 63 into shape (220,280)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-a475e42eeb94>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mX0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_meshgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mplot_mlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlp_vis_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoolwarm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoolwarm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgecolors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"k\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-75-a3f51ae7ec1c>\u001b[0m in \u001b[0;36mplot_mlp\u001b[0;34m(ax, mlp, xx, yy, **params)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_mlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontourf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 63 into shape (220,280)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__OK__ gonna come back to this as it needs faffing with and not sure it's really the main point of what we're trying to do here\n",
        "\n",
        "the custom functions need reworking for when you have more than 2 features (or I could just artificially do this with just 2 features)\n",
        "\n",
        "((or just look at the solutions))\n",
        "\n",
        "## Task 03. Glass classification"
      ],
      "metadata": {
        "id": "oMUaJFGqT1ul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# read data from google drive - fetch sharing url\n",
        "url='https://drive.google.com/file/d/1a5i2MXPjm0FE8gb9CnLHd_sDzLnfC9W7/view?usp=drive_link'\n",
        "url='https://drive.google.com/uc?id=' + url.split('/')[-2]\n",
        "\n",
        "\n",
        "data=pd.read_csv(url)\n",
        "print(data[\"Type\"].unique())\n",
        "\n",
        "X=data.iloc[:,:-1]\n",
        "y=data.iloc[:,-1]\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        " X, y, test_size=0.3, random_state=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GV0k6mq3Ud4A",
        "outputId": "d1c65007-c9ea-4a89-ef29-9449e1a52e0a"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 3 5 6 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# classify with MLP NN\n",
        "\n",
        "glass_mlp = MLPClassifier(hidden_layer_sizes=(20,20, 20), alpha= 0.01, max_iter=3000, random_state=41, activation = \"tanh\")\n",
        "\n",
        "glass_mlp.fit(X_train, y_train)\n",
        "\n",
        "# For example, to get the accuracy rate\n",
        "print('The accuracy of the test set is:',glass_mlp.score(X_test,y_test))\n",
        "# e.g. output the current Current value of the loss function\n",
        "print('The Current value of the loss function of the training set is:',glass_mlp.loss_)\n",
        "\n",
        "matrix_test = confusion_matrix(y_test,glass_mlp.predict(X_test))\n",
        "print('The confusion matrix for the training set is:\\n',matrix_test)\n",
        "\n",
        "report_test = classification_report(y_test,glass_mlp.predict(X_test))\n",
        "print(f'The classification report for the training set is: \\n {report_test}')\n",
        "\n",
        "# what did I try?\n",
        "# MLPClassifier(hidden_layer_sizes=(20,20), alpha= 0.01, max_iter=3000, random_state=41) - accuracy 0.57 (not good)\n",
        "# MLPClassifier(hidden_layer_sizes=(100,100,100,50), alpha= 0.01, max_iter=3000, random_state=41) - 0.32 (worse)\n",
        "# MLPClassifier(hidden_layer_sizes=(20,20, 20), alpha= 0.01, max_iter=3000, random_state=41) - 0.66 (better)\n",
        "# MLPClassifier(hidden_layer_sizes=(20,20, 20), alpha= 0.01, max_iter=3000, random_state=41, batch_size=10) - 0.49 (worse)\n",
        "# MLPClassifier(hidden_layer_sizes=(20,20, 20), alpha= 0.01, max_iter=3000, random_state=41, batch_size=50) - 0.57 (better but not best)\n",
        "# MLPClassifier(hidden_layer_sizes=(20,20, 20), alpha= 0.01, max_iter=3000, random_state=41, activation = \"logistic\") - 0.4 (bad)\n",
        "# MLPClassifier(hidden_layer_sizes=(20,20, 20), alpha= 0.01, max_iter=3000, random_state=41, activation = \"tanh\") - 0.68 (best so far)\n",
        "\n",
        "# is this basically trying to tell me that it's not always that good? IDEK, so tired and brain is fried"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VgiSNa7Wx7M",
        "outputId": "6d0a7664-d2e2-45e8-fac4-1f6ad3f4f740"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of the test set is: 0.676923076923077\n",
            "The Current value of the loss function of the training set is: 0.25909347709038827\n",
            "The confusion matrix for the training set is:\n",
            " [[14  6  1  0  0  0]\n",
            " [ 8 17  0  1  0  0]\n",
            " [ 5  0  2  0  0  0]\n",
            " [ 0  0  0  2  0  0]\n",
            " [ 0  0  0  0  2  0]\n",
            " [ 0  0  0  0  0  7]]\n",
            "The classification report for the training set is: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.52      0.67      0.58        21\n",
            "           2       0.74      0.65      0.69        26\n",
            "           3       0.67      0.29      0.40         7\n",
            "           5       0.67      1.00      0.80         2\n",
            "           6       1.00      1.00      1.00         2\n",
            "           7       1.00      1.00      1.00         7\n",
            "\n",
            "    accuracy                           0.68        65\n",
            "   macro avg       0.77      0.77      0.75        65\n",
            "weighted avg       0.69      0.68      0.67        65\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM classification\n",
        "import numpy as np\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "glass_svm = make_pipeline(StandardScaler(), SVC(gamma = \"auto\"))\n",
        "glass_svm.fit(X_train, y_train)\n",
        "\n",
        "matrix_test = confusion_matrix(y_test,glass_svm.predict(X_test))\n",
        "print('The confusion matrix for the training set is:\\n',matrix_test)\n",
        "\n",
        "report_test = classification_report(y_test,glass_svm.predict(X_test))\n",
        "print(f'The classification report for the training set is: \\n {report_test}')\n",
        "\n",
        "# this is slightly better than the MLP (for now - let's see if we can't get a better performance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JD0zVWZVXR-b",
        "outputId": "5f3d0be9-5c7f-497a-9227-e15e3e56909c"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The confusion matrix for the training set is:\n",
            " [[15  6  0  0  0  0]\n",
            " [ 6 19  0  0  1  0]\n",
            " [ 3  4  0  0  0  0]\n",
            " [ 0  0  0  2  0  0]\n",
            " [ 0  1  0  0  1  0]\n",
            " [ 0  0  0  0  0  7]]\n",
            "The classification report for the training set is: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.62      0.71      0.67        21\n",
            "           2       0.63      0.73      0.68        26\n",
            "           3       0.00      0.00      0.00         7\n",
            "           5       1.00      1.00      1.00         2\n",
            "           6       0.50      0.50      0.50         2\n",
            "           7       1.00      1.00      1.00         7\n",
            "\n",
            "    accuracy                           0.68        65\n",
            "   macro avg       0.63      0.66      0.64        65\n",
            "weighted avg       0.61      0.68      0.64        65\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# kNN classification\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "glass_knn = KNeighborsClassifier(n_neighbors = 3)\n",
        "glass_knn.fit(X_train, y_train)\n",
        "\n",
        "matrix_test = confusion_matrix(y_test,glass_knn.predict(X_test))\n",
        "print('The confusion matrix for the training set is:\\n',matrix_test)\n",
        "\n",
        "report_test = classification_report(y_test,glass_knn.predict(X_test))\n",
        "print(f'The classification report for the training set is: \\n {report_test}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wui7hCIXarVB",
        "outputId": "bbda0c55-c9cd-44ec-dd8b-ad075b8ad6f5"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The confusion matrix for the training set is:\n",
            " [[16  4  1  0  0  0]\n",
            " [ 8 17  0  0  1  0]\n",
            " [ 7  0  0  0  0  0]\n",
            " [ 0  0  0  2  0  0]\n",
            " [ 0  0  0  0  1  1]\n",
            " [ 1  0  0  0  0  6]]\n",
            "The classification report for the training set is: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.50      0.76      0.60        21\n",
            "           2       0.81      0.65      0.72        26\n",
            "           3       0.00      0.00      0.00         7\n",
            "           5       1.00      1.00      1.00         2\n",
            "           6       0.50      0.50      0.50         2\n",
            "           7       0.86      0.86      0.86         7\n",
            "\n",
            "    accuracy                           0.65        65\n",
            "   macro avg       0.61      0.63      0.61        65\n",
            "weighted avg       0.62      0.65      0.62        65\n",
            "\n"
          ]
        }
      ]
    }
  ]
}